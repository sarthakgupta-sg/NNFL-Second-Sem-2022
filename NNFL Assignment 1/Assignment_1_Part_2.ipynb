{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# you can use this cell to upload files or directly upload using left pane\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "7ocThJH9tcPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "ZuKLYsaq7WSK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom DataLoader (0.75 Marks)"
      ],
      "metadata": {
        "id": "WoiJzHMbh7tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for processing data samples can get messy and hard to maintain, thus we ideally want our *dataset code* to be **decoupled** from our *model training code* for better readability and modularity.\n",
        "\n",
        "For this, PyTorch provides two primitives:\n",
        "- `torch.utils.data.DataLoader`\n",
        "- `torch.utils.data.Dataset`\n",
        "\n",
        "`Dataset` stores the sample and their corresponding labels.\n",
        "\n",
        "`DataLoader` wraps an *iterable* around the `Dataset` for easy access of samples.\n",
        "\n",
        "For further reading [refer](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ],
      "metadata": {
        "id": "fx37DcsNh_CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom Dataset class extend's `Dataset` class and it must implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
        "\n",
        "We have created necessary placeholders for you. Follow the instructions to create a Custom Dataset class. "
      ],
      "metadata": {
        "id": "oweopAg4hlsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):    \n",
        "    # The __init__ function is run once when instantiating the Dataset object.\n",
        "    def __init__(self, path):\n",
        "        # Constructor for class initialization\n",
        "        super().__init__()\n",
        "        \n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        # Loading and Reading a csv file using pandas\n",
        "\n",
        "        # Storing input and output\n",
        "        self.x = \"\"\"extract first three columns of the dataframe and convert them to tensor, make sure that the datatype is float32\"\"\"\n",
        "        self.y = \"\"\"extract last column of the dataframe and convert it to tensor\"\"\"\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "\n",
        "    # The __len__ function returns the number of samples in our dataset.\n",
        "    def __len__(self):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "    \n",
        "    # The __getitem__ function loads and returns a sample from the dataset at the given index idx\n",
        "    def __getitem__(self, idx):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "    \n",
        "    def getMeanStd(self):\n",
        "        return torch.mean(self.x, dim=0, keepdims=True), torch.std(self.x, dim=0, keepdims=True)"
      ],
      "metadata": {
        "id": "XLiPie2J7HiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Dataset` retrieves our dataset’s *features and labels* one *sample at a time*. While training a model, we typically want to pass samples in **minibatches, reshuffle** the data at every epoch to reduce model overfitting, and use Python’s *multiprocessing* to speed up data retrieval.\n",
        "\n",
        "`DataLoader` is an *iterable* that abstracts this complexity for us in an easy API."
      ],
      "metadata": {
        "id": "QjnMAGxsGqj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/train.csv\"\n",
        "train_dataset = CustomDataset(train_path)\n",
        "test_path = \"/content/test.csv\"\n",
        "test_dataset = CustomDataset(test_path)"
      ],
      "metadata": {
        "id": "f-RWqhZxFgOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE STARTS HERE ###\n",
        "\"\"\"1. create two dataloaders with the name 'train_dataloader' and 'test_dataloader'.\n",
        "   2. use batch size = 64 for train dataloader and 16 for test dataloader\n",
        "   3. set shuffle = True\"\"\"\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "metadata": {
        "id": "GENXfnpY1IgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 1\n",
        "assert len(train_dataset) == 18727\n",
        "print('Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "BHqZXGaTdWr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Test case 1\n"
      ],
      "metadata": {
        "id": "VCboPYI2H9xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Test case 2\n"
      ],
      "metadata": {
        "id": "WNDPgMNKeOIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To test the shuffle feature, run this cell multiple times and observe the difference in output!\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(train_features[0])\n",
        "print(train_labels[0])"
      ],
      "metadata": {
        "id": "L6Do3Fx6JqvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Model (0.75 Marks)"
      ],
      "metadata": {
        "id": "ySKse1ipW-vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, we will be defining a class that builds a Neural Network model using the pytorch APIs.\n",
        "\n",
        " You have to use pytorch API for a [Linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) and create 4 layers of the following shape:\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "*   Layer1 = (3,32)\n",
        "*   Layer2 = (32,64)\n",
        "*   Layer3 = (64,32)\n",
        "*   Layer4 = (32,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    __init__ - In this function you are supposed to instantiate the linear layers of the required sizes\n",
        "    \n",
        "    forward - In this function you are supposed to implement the forward pass. \n",
        "    Use the Layers defined in the __init__ function to propogate the input \n",
        "    forward in the network. \n",
        "    \n",
        "    Use the relu activation for the first 3 layers and softmax for the last layer.\n",
        "\n",
        "    \n",
        "    \n",
        "Useful Links:\n",
        "- [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu)\n",
        "- [Softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax)\n",
        "- Refer to [this blog](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) after you have tried everything and feel stuck.  "
      ],
      "metadata": {
        "id": "3RFE-5PVXDRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNet(nn.Module):\n",
        "\n",
        "  def __init__(self, n=3, h1=32, h2=64, h3=32, o=1):\n",
        "    super().__init__()\n",
        "    ### YOUR CODE STARTS HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### YOUR CODE ENDS HERE ###\n",
        "  \n",
        "  def forward(self,x):\n",
        "    ### YOUR CODE STARTS HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### YOUR CODE ENDS HERE ###\n",
        "    return output"
      ],
      "metadata": {
        "id": "VTuNn_vxW4sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample test case\n",
        "torch.manual_seed(2)\n",
        "model = CustomNet()\n",
        "input=torch.randn(5,3)\n",
        "output=model(input)\n",
        "assert output.detach().numpy().shape == (5,1)\n",
        "assert output.dim() == 2\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GsacBRgZd_8",
        "outputId": "1820c776-cf8d-47a6-807f-f55cbd035ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Loss Function (0.25 Marks)"
      ],
      "metadata": {
        "id": "eMbwckPHe5kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often when implementing a deep learning model from papers,  we encounter loss functions that are not part of the framework as these loss functions are specialized down to the particular model used in the research paper. Hence the frameworks can’t add all of them to their libraries, and it is up to the user/researcher to define them for the task."
      ],
      "metadata": {
        "id": "pgYzirPne9LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try to implement our own `Binary Cross Entropy Loss` function.\n",
        "\n",
        "While there are various methods to do use, we will use the following approach.\n",
        "\n",
        "To implement a custom loss function we must:\n",
        "- Extend `nn.Module` to inherit standard properties of computational graphs for automatic backward pass.\n",
        "- Implement \n",
        "    - `__init__()` : Constructor of our loss function.\n",
        "    - `forward()` : For performing calculations for computing loss.\n",
        "\n",
        "For further reading [refer](https://pdf.co/blog/deep-learning-pytorch-custom-loss-function)"
      ],
      "metadata": {
        "id": "hJZVWYezfbHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBCE(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Constructor for class initialization\n",
        "        super().__init__()\n",
        "    def forward(self, output, target):\n",
        "        # Loss Calculation\n",
        "        # Clamping output to avoid log(0)==NaN\n",
        "        output = torch.clamp(output, 1e-7, 1-(1e-7))\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "        return loss"
      ],
      "metadata": {
        "id": "9LUB5odLgryf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test case 1\n",
        "bce = CustomBCE()\n",
        "x1 = torch.tensor([1.0])\n",
        "x2 = torch.tensor([0.0])\n",
        "assert torch.isclose(bce(x1,x2), torch.tensor(15.9424), atol = 0.2) \n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "p8n8_H27iQY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Test case 1\n"
      ],
      "metadata": {
        "id": "lBGt18qNjCqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put everything together"
      ],
      "metadata": {
        "id": "beTr22g7cHE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will write a function to train our model.\n",
        "\n",
        "\n",
        "To train the model do the following:\n",
        "\n",
        "\n",
        "*   Clear the gradients \n",
        "*   Normalize the input\n",
        "*   Do a forward pass \n",
        "*   Calculate the loss\n",
        "*   Do a backward pass\n",
        "*   Perform gradient descent\n",
        "\n",
        "Refer to the following links if you need help\n",
        "\n",
        "\n",
        "*   [CIFAR10-tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)\n",
        "*   [NN tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)\n",
        "*   [Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)"
      ],
      "metadata": {
        "id": "SFfxohCecXiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing"
      ],
      "metadata": {
        "id": "eHbpjXF1syYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = train_dataset.getMeanStd()\n",
        "# Function to normalize using train datasets mean and std only.\n",
        "def normalize(x):\n",
        "    x = (x-mean)/std\n",
        "    return x\n",
        "\n",
        "print(mean.shape, std.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRZYVq66Yg1X",
        "outputId": "da27d281-9d04-4607-f540-b09e5f2d2cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3]) torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (1.25 Marks)"
      ],
      "metadata": {
        "id": "iGlXGEUQwcBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, test_dataloader,\n",
        "                max_epochs, criterion, optimizer):\n",
        "\n",
        "  losses=[]\n",
        "  model.train()\n",
        "  for epoch in range(max_epochs):\n",
        "    epoch_loss = 0\n",
        "    for x, labels in train_dataloader:\n",
        "      ### YOUR CODE STARTS HERE ###\n",
        "      \"\"\"1. clear the gradients\n",
        "         2. normalize input\n",
        "         3. do a forward pass\n",
        "         4. calculate loss\n",
        "         5. do a backward pass\n",
        "         6. perform gradient descent\n",
        "      \"\"\"\n",
        "      ### YOUR CODE ENDS HERE ###  \n",
        "      epoch_loss += loss.item()\n",
        "    \n",
        "    if (epoch+1)%10==0:\n",
        "        print(\"loss at epoch: \"+str(epoch)+\" = \"+str((epoch_loss)/len(train_dataloader)))\n",
        "    losses.append(epoch_loss/len(train_dataloader))\n",
        "  return losses"
      ],
      "metadata": {
        "id": "AiQC5rrtcE8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(101)\n",
        "model = # use custom model class\n",
        "criterion = # use custom loss class\n",
        "optimizer = # refer to torch.optim.SGD and set learning rate = 0.1"
      ],
      "metadata": {
        "id": "E3IIbZPrfAz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "losses = train_model(model, train_dataloader, test_dataloader, 100, criterion, optimizer)"
      ],
      "metadata": {
        "id": "o_TAwOoafT9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "plt.plot(losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.title(\"Learning rate =\" + str(0.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DNOq-9C8feQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Your training accuracy should be in between 0.57-0.63, and your test accuracy should be in between 0.55-0.60.\n",
        "\n",
        "Otherwise, you might want to recheck your code. "
      ],
      "metadata": {
        "id": "QlXaEn87txeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    for x, labels in train_dataloader:\n",
        "        x = normalize(x)\n",
        "        y_pred=model(x)\n",
        "        y_pred_class=y_pred.round()\n",
        "        accuracy +=(y_pred_class.eq(labels).sum())\n",
        "    print('Acc on train dataset:', accuracy.item()/len(train_dataset))"
      ],
      "metadata": {
        "id": "nyaDjCpWjxob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): \n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    for x, labels in test_dataloader:\n",
        "        x = normalize(x)\n",
        "        y_pred=model(x)\n",
        "        y_pred_class=y_pred.round()\n",
        "        accuracy +=(y_pred_class.eq(labels).sum())\n",
        "    print('Acc on test dataset:', accuracy.item()/len(test_dataset))"
      ],
      "metadata": {
        "id": "wNd-r7wcoVIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (optional) \n",
        "### This is the plot that we obtain after training for 5000 epochs. \n",
        "\n",
        "*No need to run this!*"
      ],
      "metadata": {
        "id": "qsQeZgb8cY1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "losses = train_model(model, train_dataloader, test_dataloader, 5000, criterion, optimizer)"
      ],
      "metadata": {
        "id": "g8Pk6vyvb2oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.title(\"Learning rate =\" + str(0.1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2aIRADWUfM8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}